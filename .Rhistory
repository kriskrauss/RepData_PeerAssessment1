confusionMatrix(training$classe, predict(modelFit,training.1))
confusionMatrix(training.1$classe, predict(modelFit,training.1))
cor.matrix<-cor(training.1)
View(training.1)
View(training.1[,-1])
cor.matrix<-cor(training.1[,-1])
cor.matrix<-cor(training.1[,-c(1,55)])
corrplot(cor.matrix, method="ellipse", type="lower")
library(corrplot)
corrplot(cor.matrix, method="ellipse", type="lower")
cor.matrix
cor.matrix[corr.matrix>0]
class(cor.matrix)
diag(corr.matrix)<-0
diag(cor.matrix)<-0
which(cor.matrix>0.8, arr.ind=T)
length(which(cor.matrix>0.8, arr.ind=T))
dim(which(cor.matrix>0.8, arr.ind=T))
confusionMatrix(training.1$classe, predict(modelFit,training.1))
?rfcv
rfcv(training.1[,-55], training.1[,55])
View(training.1)
importance(modelFit)
names(modelFit)
?trainControl
varImp(modelFit)
varImp(modelFit, scale=FALSE)
rf.cv<-rfcv(training.1[,-55], training.1[,55])
with(rf.cv, plot(n.var, error.cv))
names(rf.cv)
with(rf.cv, plot(n.var, error.cv, log="x", type="o", lwd=2))
rf.cv
summary(rf.cv)
print(rf.cv)
with(rf.cv, plot(n.var, error.cv, log="x", type="o", lwd=2, xlab="Number of variables", ylab="CV Error"))
with(rf.cv, plot(n.var, error.cv, log="x", type="o", lwd=2, xlab="Number of variables", ylab="CV Error"))
plot(modelFit)
modelFit
featurePlot(x=training.1[,2:13], y=training.1$classe, plot="box", layout=c(4,3), auot.key=list(columns=5))
which(cor.matrix>0.8, arr.ind=T)
which(cor.matrix>0.8, arr.ind=T)[1]
which(cor.matrix>0.8, arr.ind=T)[]
which(cor.matrix>0.8, arr.ind=T)[,1]
unique(which(cor.matrix>0.8, arr.ind=T)[,1])
which(cor.matrix>0.8, arr.ind=T)[,1]
which(cor.matrix>0.9, arr.ind=T)
featurePlot(x=training.1[,c(2,5,10,34,47)], y=training.1$classe, plot="box", layout=c(2,3), auot.key=list(columns=5))
varImp(modelFit)
confusionMatrix(training.1$classe, predict(modelFit,training.1))
require(knitr)
require(markdown)
install.packages("markdown")
install.packages("knitr")
require(markdown)
cwd
?cd
?setwd
getwd()
setwd("C:/krishna/coursera/predictivemachinelearning")
knit('PredictingExercises.Rmd', 'PredictingExercises.md')
knit('PredictingExercises.Rmd', 'PredictingExercises.md')
knit('PredictingExercises.Rmd', 'PredictingExercises.md')
markdownToHTML('PredictingExercises.md', 'PredictingExercises.html')
browseURL(paste('file://', file.path(getwd(),'PredictingExercises.html'), sep=''))
knit('PredictingExercises.Rmd', 'PredictingExercises.md')
markdownToHTML('PredictingExercises.md', 'PredictingExercises.html')
browseURL(paste('file://', file.path(getwd(),'PredictingExercises.html'), sep=''))
knit('PredictingExercises.Rmd', 'PredictingExercises.md')
markdownToHTML('PredictingExercises.md', 'PredictingExercises.html')
browseURL(paste('file://', file.path(getwd(),'PredictingExercises.html'), sep=''))
corrplot(cor.matrix, method="ellipse", type="lower")
getwd()
setwd("C:/Users/krishna/machinelearning")
knit('README.Rmd', 'README.md')
markdownToHTML('README.md', 'PredictingExercises.html')
browseURL(paste('file://', file.path(getwd(),'PredictingExercises.html'), sep=''))
getwd()
setwd("C:/Users/krishna/practicalmachinelearning")
knit('README.Rmd', 'README.md')
markdownToHTML('README.md', 'PredictingExercises.html')
browseURL(paste('file://', file.path(getwd(),'PredictingExercises.html'), sep=''))
setwd("C:/Users/krishna/machinelearning")
knit('README.Rmd', 'README.md')
markdownToHTML('README.md', 'PredictingExercises.html')
browseURL(paste('file://', file.path(getwd(),'PredictingExercises.html'), sep=''))
setwd("C:/krishna/coursera/predictivemachinelearning")
save(modelFit, file="modelFit.RData")
save(rf.cv, file="rf.cv.RData")
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
View(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
str(vowel.train)
View(vowel.train)
set.seed(33833)
library(caret)
install.packages("caret")
library(caret)
?train()
modelRF<-train(y~., data=vowel.train, method="rf")
install.packages("randomForest")
install.packages("e1071")
modelRF<-train(y~., data=vowel.train, method="rf")
modelGBM<-train(y~., data=vowel.train, method="gbm")
predictRF<-predict(modelRF, newdata=vowel.test)
predictGBM<-predict(modelGBM, newdata=vowel.test)
predictRF
View(vowel.test)
confusionMatrix(predictRF,vowel.test$y)
confusionMatrix(predictGBM,vowel.test$y)
?confusionMatrix
install.packages("agreement")
library(agreement)
install.packages("Agreement")
library(Agreement)
?accuracy
install.packages("forecast")
library(forecast)
?accuracy
accuracy(predictRF, vowel.test$y)
compvector<-predictRF==predictGBM
compvector
dim(compvector)
length(compvector)
length(compvector==TRUE)
length(!compvector)
table(comvector)
table(compvector)
325/462
rm(list=ls())
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData=data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training=adData[inTrain,]
testing=adData[-inTrain,]
set.seed(62433)
View(training)
modelRF<-train(diagnosis.~, data=training, method="rf")
modelRF<-train(diagnosis . ~, data=training, method="rf")
modelRF<-train(training$diagnosis . ~, data=training, method="rf")
quit
install.packages("randomForest")
install.packages("gbm")
install.packages("lda")
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
modelGBM<-train(diagnosis ~., method="gbm", data=training)
set.seed(62433)
modelGBM<-train(diagnosis ~., method="gbm", data=training, verbose=FALSE)
modelRF<-train(diagnosis ~., method="rf", data=training)
modelLDA<-train(diagnosis ~., method="lda", data=training)
confusionMatrix(predict(modelGBM,newdata=testing), testing$diagnosis)
confusionMatrix(predict(modelLDA,newdata=testing), testing$diagnosis)
confusionMatrix(predict(modelRF,newdata=testing), testing$diagnosis)
?caretEnsemble
library(caret)
?caretEnsemble
?caret
modelGBM$results
modelGBM$results$Accuracy
mean(modelGBM$results$Accuracy)
predictGBM<-predict(modelGBM, newdata=testing)
predictLDA<-predict(modelLDA, newdata=testing)
predictRF<-predict(modelRF, newdata=testing)
newtrain<-data.frame(GBM=predictGBM, LDA=predictLDA, RF=predictRF)
modelEnsemble<-train(testing$diagnosis ~ ., method="rf", data=newtrain)
modelEnsemble
modelEnsemble$results
modelEnsemble$results$Accuracy
mean(modelEnsemble$results$Accuracy)
get.seed()
.Ranson.seed
.Random.seed
predict(modelEnsemble, testing$diagnosis)
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
install.packages("lasso")
?plot.enet
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
set.seed(325)
View(training)
modelSVM<-svm(CompressiveStrength~., data=training)
predictSVM<-predict(modelSVM, testing)
confusionMatrix(predictSVM, testing$CompressiveStrength)
predictSVM
predictSVM<-predict(modelSVM, testing[,-9])
predictSVM
predictSVM<-predict(modelSVM, testing[,-9])
tab<-table(pred=predictSVM, true=testing[,9])
tab
sqrt(mean(predictSVM-testing$CompressiveStrength)^2))
sqrt(mean(predictSVM-testing$CompressiveStrength)^2)
error<-predictSVM-testing$CompressiveStrength
sqrt(mean(error^2))
sqrt(mean((predictSVM-testing$CompressiveStrength)^2))
help(forecast)
library(forecast)
help(forecast)
rm(list=ls())
library(lubridate)
install.packages("lubridate")
library(lubridate)
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?read.data()
?read
dat = read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", header=TRUE)
View(dat)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats()
bats(training)
bats(tstrain)
modelBATS<-bats(tstrain)
names(modelBATS)
plot(forecast(modelBATS))
accuracy(modelBATS, ts(testing$visitsTumblr))
View(training)
View(testing)
forecast(modelBATS, h=235, level=c(95))
forecast(modelBATS, h=235, level=c(.95))
mydata<-forecast(modelBATS, h=235, level=c(.95))
mydata$level
mydata$method
mydata$fitted
mydata$residuals
plot(forecast(modelBATS, h=235, level=c(.95)))
install.packages("lars")
forecast(modelBATS, h=235, level=c(95))
summary(mydata)
library(lars)
help(lars)
library(glmnet)
install.packages("glmnet")
library(glmnet)
help(glmnet)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
View(training)
lasso.path<-lars(training$CompressiveStrength, training[,-9], type="lasso")
lasso.path<-lars(training[,-9], training$CompressiveStrength, type="lasso")
str(training)
modelLasso<-train(CompressiveStrength~., method="lasso", data=training)
modelLasso
?plot.enet
plot(modelLasso, xvar="penalty")
plot(modelLasso, xvar="fraction")
plot(modelLasso, xvar="fraction")
names(modelLasso)
plot(modelLasso, xvar="step")
plot(modelLasso, xvar="step")
modelLasso$results
modelLasso$bestTune
modelLasso$coefnames
modelLasso$xlevels
modelLasso$xlevels()
modelLasso$xlevels[]
modelLasso$maximize
modelLasso$finalModel
coef(modelLasso$finalModel)
coefnames(modelLasso$finalModel)
modelLasso$finalModel$coefnames
modelLasso$coefnames
lasso.path<-lars(training, training$CompressiveStrength, type="lasso", trace=TRUE)
str(training)
training$Age<-as.numeric(training$Age)
lasso.path<-lars(training, training$CompressiveStrength, type="lasso", trace=TRUE)
str(training)
lasso.path<-lars(training$Cement+training$BlastFurnaceSlag+$training$FlyAsh, training$CompressiveStrength, type="lasso", trace=TRUE)
mydata<-as.matrix(training[,-9])
mydata
lasso.path<-lars(mydata, training$CompressiveStrength, type="lasso", trace=TRUE)
names(lasso.path)
plot(lasso.path)
?lassoPlot
lasso.stepwise<-lars(mydata, training$CompressiveStrength, type="stepwise", trace=TRUE)
lasso.stepwise
View(mydata)
?enet
model.enet<-enet(mydata, training$CompressiveStrength, lambda=0, trace=TRUE)
plot(model.enet)
plot(model.enet, use.color=TRUE)
model.enet
names(model.enet)
model.enet$penalty
model.enet$actions
model.enet$L1norm
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
View(training)
set.seed(233)
modelLasso<-train(CompressiveStrength~., method="lasso", data=training)
names(modelLasso)
modelLasso
modelLasso$finalModel
par(mfrow=c(1,2))
plot(modelLasso$finalModel, "norm", label=TRUE)
plot.enet(modelLasso$finalModel, "norm", label=TRUE)
?plot.enet
plot.enet(modelLasso$finalModel, xvar="penalty", use.color=TRUE)
plot.enet(modelLasso$finalModel, xvar="L1norm", use.color=TRUE)
names(modelLasso$finalModel)
modelLasso$finalModel$obsLevels
modelLasso$finalModel$lambda
modelLasso$finalModel$problemType
modelLasso$finalModel$xNames
modelLasso$finalModel$actions
rm(list=ls())
dat = read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", header=TRUE)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
modelBATS<-bats(tstrain)
library(forecast)
modelBATS<-bats(tstrain)
mydata<-forecast(modelBATS, h=235, level=c(95))
mydata
names(modelBATS)
names(mydata)
View(testing)
mytest<-(testing$visitsTumblr > mydata$lower & testing$visitsTumblr < mydata$upper)
mytest
table(mytest)
226/(226+9)
rm(list=ls())
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
View(training)
modelRF<-train(diagnosis~., method="rf", data=training)
modelGBM<-train(diagnosis.~, method="gbm", data=training, verbose=FALSE)
modelGBM<-train(diagnosis~., method="gbm", data=training, verbose=FALSE)
modelLDA<-train(diagnosis~., method="lda", data=training)
confusionMatrix(predict(modelRF,testing), testing$diagnosis)
confusionMatrix(predict(modelLDA,testing), testing$diagnosis)
confusionMatrix(predict(modelGBM,testing), testing$diagnosis)
predictRF<-predict(modelRF,testing)
predictLDA<-predict(modelLDA,testing)
predictGBM<-predict(modelGBM,testing)
predictRF
confusionMatrix(predictRF,testing$diagnosis)
mydata<-data.frame(predictRF,predictGBM,predictLDA)
View(mydata)
modelC<-train(testing$diagnosis~., method="rf", data=mydata)
modelC
confusionMatrix(predict(modelC,mydata), testing$diagnosis)
modelRF
modelRF$Accuracy
names(modelRF)
model$results
modelRF$results
modelRF$results$Accuracy
modelRF$finalModel
names(modelRF$finalModel)
modelRF$finalModel$predicted
confusonMatrix(modelRF$finalModel$predicted, training$diagnosis)
confusionMatrix(modelRF$finalModel$predicted, training$diagnosis)
modelRF$finalModel$err.rate
names(modelRF$finalModel)
modelRF$finalModel$test
modelRF$finalModel$oob.times
modelRF$finalModel$classes
modelRF$finalModel$importance
modelRF$finalModel$inbag
names(modelRF$finalModel)
modelRF$finalModel$proximity
modelRF$finalModel$mtry
modelRF$finalModel
modelLDA$finalModel
confusionMatrix(modelRF$finalModel$predicted, training$diagnosis)
confusionMatrix(modelLDA$finalModel$predicted, training$diagnosis)
confusionMatrix(modelLDA$finalModel$predicted, training$diagnosis)
names(modelLDA)
modelLDA$pred
modelLDA$results
modelGBM$results
modelGBM$results$Accuracy
modelGBM$finalModel
confusionMatrix(modelGBM$finalModel$predicted, training$diagnosis)
names(modelGBM$finalModel)
modelGBM$finalModel$train.error
modelGBM$finalModel$valid.error
modelGBM$finalModel$fit
confusionMatrix(predict(modelGBM$finalModel,training), training$diagnosis)
confusionMatrix(predict(modelGBM,training), training$diagnosis)
modelC
names(modelC)
modelC$results
modelC$results$pred
names(modelC$results)
modelC$results$Accuracy
confusionMatrix(modelC$finalModel$predicted, testing$diagnosis)
modelGBM$finalModel$fit
modelGBM$finalModel
names(modelGBM$finalModel)
activity<-read.csv("activity.zip", header=TRUE)
setwd
? setwd
setwd('C:\Users\krishna\Documents\GitHub\RepData_PeerAssessment1')
setwd('C:/Users/krishna/Documents/GitHub/RepData_PeerAssessment1')
activity<-read.csv("activity.zip", header=TRUE)
>unz
?unz
activity<-read.csv(unz("activity.zip"), header=TRUE)
unz("activity.zip")
unz("activity.zip", "activity.dat")
activity<-read.csv(unz("activity.zip", "activity.dat", sep="|"), header=TRUE)
activity<-read.csv(unz("activity.zip", "activity.dat"), header=TRUE)
activity<-read.csv(unz("activity.zip", "activity.csv"), header=TRUE)
top(activity)
activity
head(activity)
close()
head(activity)
head(activity, 20)
head(activity, 100)
head(activity, 400)
type(activity)
datatype(activity)
typeof(activity)
class(activity)
library(plyr)
ddply(activity, .(date), meansteps=mean(steps))
ddply(activity, .(date), summarize, meansteps=mean(steps))
activity.cols()
activity.colnames()
colnames(activity)
activity[date=='2012-11-30']
activity[activity$date=='2012-11-30',]
meansteps<-ddply(activity, .(date), summarize, meansteps=mean(steps))
colnames(meansteps)
hist(meansteps$meansteps)
totalsteps<-ddply(activity, .(date), summarize, totsteps=sum(steps))
hist(totalsteps$ttosteps)
hist(totalsteps$totsteps)
daywisesteps<-ddply(activity, .(date), summarize, totsteps=sum(steps), meansteps=mean(steps), mediansteps=median(steps))
hist(daywisesteps$totsteps)
daywisesteps
daywisesteps<-ddply(activity, .(date), summarize, totsteps=sum(steps, na.rm=T), meansteps=mean(steps, na.rm=T), mediansteps=median(steps, na.rm=T))
daywisesteps
hist(daywisesteps$totsteps)
intervalavg<-ddply(activity, .(interval), summarize, avgsteps=avg(steps, na.rm=T))
intervalavg<-ddply(activity, .(interval), summarize, avgsteps=average(steps, na.rm=T))
intervalavg<-ddply(activity, .(interval), summarize, avgsteps=mean(steps, na.rm=T))
plot.ts(intervalavg)
intervalavg
?plot.ts
?plot
plot(x<-intervalavg$interval, y<-intervalavg$avgsteps, type="l")
plot(intervalavg$interval, intervalavg$avgsteps, type="l")
intervalavg[intervalavg$avgsteps == max(intervalavg$avgsteps), ]
activity.nona<-na.omit(activity)
activity.full<-activity
